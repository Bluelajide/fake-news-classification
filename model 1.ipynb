{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\quang\\anaconda3\\lib\\site-packages (4.51.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\quang\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\quang\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\quang\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\quang\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: seaborn in c:\\users\\quang\\anaconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: wordcloud in c:\\users\\quang\\anaconda3\\lib\\site-packages (1.9.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\quang\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from transformers) (0.31.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\quang\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: click in c:\\users\\quang\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\quang\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\quang\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers nltk pandas numpy matplotlib seaborn wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\quang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\quang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape and Size of News Data: (20800, 5)\n",
      "News Data columns Index(['id', 'title', 'author', 'text', 'label'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "news_d = pd.read_csv(\"train.csv\")\n",
    "\n",
    "print(\"Shape and Size of News Data:\", news_d.shape)\n",
    "print(\"News Data columns\", news_d.columns)\n",
    "\n",
    "# by using df.head(), we can immediately familiarize ourselves with the dataset. \n",
    "news_d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    20242.000000\n",
       "mean        12.420709\n",
       "std          4.098735\n",
       "min          1.000000\n",
       "25%         10.000000\n",
       "50%         13.000000\n",
       "75%         15.000000\n",
       "max         72.000000\n",
       "Name: title, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Text Word startistics: min.mean, max and interquartile range\n",
    "txt_length = news_d.text.str.split().str.len()\n",
    "txt_length.describe()\n",
    "\n",
    "#Title statistics \n",
    "title_length = news_d.title.str.split().str.len()\n",
    "title_length.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Unreliable\n",
      "0: Reliable\n",
      "Distribution of labels:\n",
      "label\n",
      "1    10413\n",
      "0    10387\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "1    50.0\n",
      "0    50.0\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"label\", data=news_d);\n",
    "print(\"1: Unreliable\")\n",
    "print(\"0: Reliable\")\n",
    "print(\"Distribution of labels:\")\n",
    "print(news_d.label.value_counts());\n",
    "\n",
    "print(round(news_d.label.value_counts(normalize=True),2)*100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants that are used to sanitize the datasets \n",
    "\n",
    "column_n = ['id', 'title', 'author', 'text', 'label']\n",
    "remove_c = ['id','author']\n",
    "categorical_features = []\n",
    "target_col = ['label']\n",
    "text_f = ['title', 'text']\n",
    "\n",
    "# Clean Datasets\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from collections import Counter\n",
    "\n",
    "ps = PorterStemmer()\n",
    "wnl = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stopwords_dict = Counter(stop_words)\n",
    "\n",
    "# Removed unused columns\n",
    "def remove_unused_c(df,column_n=remove_c):\n",
    "    df = df.drop(column_n,axis=1)\n",
    "    return df\n",
    "\n",
    "# Impute null values with None\n",
    "def null_process(feature_df):\n",
    "    for col in text_f:\n",
    "        feature_df.loc[feature_df[col].isnull(), col] = \"None\"\n",
    "    return feature_df\n",
    "\n",
    "def clean_dataset(df):\n",
    "    # remove unused column\n",
    "    df = remove_unused_c(df)\n",
    "    #impute null values\n",
    "    df = null_process(df)\n",
    "    return df\n",
    "\n",
    "# Cleaning text from unused characters\n",
    "def clean_text(text):\n",
    "    text = str(text).replace(r'http[\\w:/\\.]+', ' ')  # removing urls\n",
    "    text = str(text).replace(r'[^\\.\\w\\s]', ' ')  # remove everything but characters and punctuation\n",
    "    text = str(text).replace('[^a-zA-Z]', ' ')\n",
    "    text = str(text).replace(r'\\s\\s+', ' ')\n",
    "    text = text.lower().strip()\n",
    "    #text = ' '.join(text)    \n",
    "    return text\n",
    "\n",
    "## Nltk Preprocessing include:\n",
    "# Stop words, Stemming and Lemmetization\n",
    "# For our project we use only Stop word removal\n",
    "def nltk_preprocess(text):\n",
    "    text = clean_text(text)\n",
    "    wordlist = re.sub(r'[^\\w\\s]', '', text).split()\n",
    "    #text = ' '.join([word for word in wordlist if word not in stopwords_dict])\n",
    "    #text = [ps.stem(word) for word in wordlist if not word in stopwords_dict]\n",
    "    text = ' '.join([wnl.lemmatize(word) for word in wordlist if word not in stopwords_dict])\n",
    "    return  text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>house dem aide didnt even see comeys letter ja...</td>\n",
       "      <td>house dem aide didnt even see comeys letter ja...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flynn hillary clinton big woman campus breitbart</td>\n",
       "      <td>ever get feeling life circle roundabout rather...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>truth might get fired</td>\n",
       "      <td>truth might get fired october 29 2016 tension ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15 civilian killed single u airstrike identified</td>\n",
       "      <td>video 15 civilian killed single u airstrike id...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iranian woman jailed fictional unpublished sto...</td>\n",
       "      <td>print iranian woman sentenced six year prison ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  house dem aide didnt even see comeys letter ja...   \n",
       "1   flynn hillary clinton big woman campus breitbart   \n",
       "2                              truth might get fired   \n",
       "3   15 civilian killed single u airstrike identified   \n",
       "4  iranian woman jailed fictional unpublished sto...   \n",
       "\n",
       "                                                text  label  \n",
       "0  house dem aide didnt even see comeys letter ja...      1  \n",
       "1  ever get feeling life circle roundabout rather...      0  \n",
       "2  truth might get fired october 29 2016 tension ...      1  \n",
       "3  video 15 civilian killed single u airstrike id...      1  \n",
       "4  print iranian woman sentenced six year prison ...      1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform data cleaning on train and test dataset by calling clean_dataset function\n",
    "df = clean_dataset(news_d)\n",
    "# apply preprocessing on text through apply method by calling the function nltk_preprocess\n",
    "df[\"text\"] = df.text.apply(nltk_preprocess)\n",
    "# apply preprocessing on title through apply method by calling the function nltk_preprocess\n",
    "df[\"title\"] = df.title.apply(nltk_preprocess)\n",
    "\n",
    "# Dataset after cleaning and preprocessing step\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\quang\\anaconda3\\lib\\site-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\quang\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from transformers) (0.31.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\quang\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\quang\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: torch in c:\\users\\quang\\anaconda3\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\quang\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\quang\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\quang\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\quang\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "! pip install -U transformers\n",
    "! pip install -U torch\n",
    "\n",
    "import torch\n",
    "from transformers.file_utils import is_tf_available, is_torch_available\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    \"\"\"\n",
    "    Helper function for reproducible behavior to set the seed in ``random``, ``numpy``, ``torch`` and/or ``tf`` (if\n",
    "    installed).\n",
    "\n",
    "    Args:\n",
    "        seed (:obj:`int`): The seed to set.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if is_torch_available():\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        # ^^ safe to call this function even if cuda is not available\n",
    "    if is_tf_available():\n",
    "        import tensorflow as tf\n",
    "\n",
    "        tf.random.set_seed(seed)\n",
    "\n",
    "set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model we gonna train, base uncased BERT\n",
    "# check text classification models here: https://huggingface.co/models?filter=text-classification\n",
    "model_name = \"bert-base-uncased\"\n",
    "# max sequence length for each document/sentence sample\n",
    "max_length = 512\n",
    "\n",
    "# load the tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = news_d[news_d['text'].notna()]\n",
    "news_df = news_df[news_df[\"author\"].notna()]\n",
    "news_df = news_df[news_df[\"title\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, test_size=0.2, include_title=True, include_author=True):\n",
    "  texts = []\n",
    "  labels = []\n",
    "  for i in range(len(df)):\n",
    "    text = df[\"text\"].iloc[i]\n",
    "    label = df[\"label\"].iloc[i]\n",
    "    if include_title:\n",
    "      text = df[\"title\"].iloc[i] + \" - \" + text\n",
    "    if include_author:\n",
    "      text = df[\"author\"].iloc[i] + \" : \" + text\n",
    "    if text and label in [0, 1]:\n",
    "      texts.append(text)\n",
    "      labels.append(label)\n",
    "  return train_test_split(texts, labels, test_size=test_size)\n",
    "\n",
    "train_texts, valid_texts, train_labels, valid_labels = prepare_data(news_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14628 14628\n",
      "3657 3657\n"
     ]
    }
   ],
   "source": [
    "print(len(train_texts), len(train_labels))\n",
    "print(len(valid_texts), len(valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the dataset, truncate when passed `max_length`, \n",
    "# and pad with 0's when less than `max_length`\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=max_length)\n",
    "valid_encodings = tokenizer(valid_texts, truncation=True, padding=True, max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsGroupsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# convert our tokenized data into a torch Dataset\n",
    "train_dataset = NewsGroupsDataset(train_encodings, train_labels)\n",
    "valid_dataset = NewsGroupsDataset(valid_encodings, valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    print(confusion_matrix(labels, preds))\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\users\\quang\\anaconda3\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\quang\\anaconda3\\lib\\site-packages (4.51.3)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\quang\\anaconda3\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\quang\\anaconda3\\lib\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from accelerate) (2.7.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from accelerate) (0.31.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\quang\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\quang\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\quang\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\quang\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate) (75.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\quang\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\quang\\anaconda3\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "! pip install -U accelerate transformers\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=4,              # total number of training epochs\n",
    "    per_device_train_batch_size=10,  # batch size per device during training\n",
    "    per_device_eval_batch_size=20,   # batch size for evaluation\n",
    "    warmup_steps=300,                # number of warmup steps for learning rate scheduler\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
    "    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
    "    logging_steps=200,               # log & save weights each logging_steps\n",
    "    save_steps=200,\n",
    "    eval_strategy=\"steps\",          # evaluate each `logging_steps`\n",
    "    learning_rate=1e-5,             # learning rate\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=valid_dataset,          # evaluation dataset\n",
    "    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],  # stop if no improvement for 3 evals\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\quang\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='5852' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/5852 6:00:43 < 29:13:44, 0.05 it/s, Epoch 0/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.589000</td>\n",
       "      <td>0.318867</td>\n",
       "      <td>0.906207</td>\n",
       "      <td>0.897304</td>\n",
       "      <td>0.884250</td>\n",
       "      <td>0.890730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.103000</td>\n",
       "      <td>0.005551</td>\n",
       "      <td>0.999180</td>\n",
       "      <td>0.998736</td>\n",
       "      <td>0.999367</td>\n",
       "      <td>0.999052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>0.008015</td>\n",
       "      <td>0.998633</td>\n",
       "      <td>0.998734</td>\n",
       "      <td>0.998102</td>\n",
       "      <td>0.998418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.010904</td>\n",
       "      <td>0.998086</td>\n",
       "      <td>0.997472</td>\n",
       "      <td>0.998102</td>\n",
       "      <td>0.997787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>0.013211</td>\n",
       "      <td>0.997266</td>\n",
       "      <td>0.998098</td>\n",
       "      <td>0.995572</td>\n",
       "      <td>0.996833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1916  160]\n",
      " [ 183 1398]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\quang\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2074    2]\n",
      " [   1 1580]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\quang\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2074    2]\n",
      " [   3 1578]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\quang\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2072    4]\n",
      " [   3 1578]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\quang\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2073    3]\n",
      " [   7 1574]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1000, training_loss=0.1455344114303589, metrics={'train_runtime': 21670.2315, 'train_samples_per_second': 2.7, 'train_steps_per_second': 0.27, 'total_flos': 2631110553600000.0, 'train_loss': 0.1455344114303589, 'epoch': 0.683526999316473})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\quang\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='183' max='183' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [183/183 17:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2074    2]\n",
      " [   1 1580]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.005551148671656847,\n",
       " 'eval_accuracy': 0.9991796554552912,\n",
       " 'eval_precision': 0.9987357774968394,\n",
       " 'eval_recall': 0.9993674889310563,\n",
       " 'eval_f1': 0.9990515333544103,\n",
       " 'eval_runtime': 1041.7899,\n",
       " 'eval_samples_per_second': 3.51,\n",
       " 'eval_steps_per_second': 0.176,\n",
       " 'epoch': 0.683526999316473}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fake-news-bert-base-uncased\\\\tokenizer_config.json',\n",
       " 'fake-news-bert-base-uncased\\\\special_tokens_map.json',\n",
       " 'fake-news-bert-base-uncased\\\\vocab.txt',\n",
       " 'fake-news-bert-base-uncased\\\\added_tokens.json',\n",
       " 'fake-news-bert-base-uncased\\\\tokenizer.json')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving the fine tuned model & tokenizer\n",
    "model_path = \"fake-news-bert-base-uncased\"\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(text, convert_to_label=False):\n",
    "    # prepare our text into tokenized sequence\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(device)\n",
    "    # perform inference to our model\n",
    "    outputs = model(**inputs)\n",
    "    # get output probabilities by doing softmax\n",
    "    probs = outputs[0].softmax(1)\n",
    "    # executing argmax function to get the candidate label\n",
    "    d = {\n",
    "        0: \"Reliable\",\n",
    "        1: \"Fake\"\n",
    "    }\n",
    "    if convert_to_label:\n",
    "      return d[int(probs.argmax())]\n",
    "    else:\n",
    "      return int(probs.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_prediction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m real_news \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124mKeiser Report: Trump is USA\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms antique hero. Clinton will be next president,nan,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrump is USA\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms antique hero. Clinton will be next president 08.11.2016 | Source: AP photo FBI Director James Comey said on November 6 that his department would not be criminally charging Hillary Clinton for revelations found in her email correspondence. Earlier, however, the FBI had flagged Clinton\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms email case as a file of high priority. It was said that the FBI had collected a lot of evidence. All of a sudden, it was announced that Clinton would be cleared. Pravda.Ru asked political scientist and publicist Leonid Krutakov to comment on such a development. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas it a though-out move to show that Clinton is not guilty?\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDid you expect a criminal case against Clinton right before the election? I thought of such a plan if Trump were winning, but now that they have cleared her name, it means that Hillary Clinton will win the election. One can be sure for 100 percent that Hillary Clinton will be the next President of the United States of America. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI do not think that the FBI Director made that decision independently. This is a political figure, this is a job to which people are appointed by someone else. It is stupid to believe that one FBI director will stand up against the whole elite that prints money and runs business and international politics. The times of ancient heroes have passed. Trump has tried to become one. He has proclaimed a new era, not only in America but in the world, and the electorate that has consolidated around Trump will not go anywhere after the election. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOne needs another war and another threat to America to make Trump\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms electorate change their mind. As we remember, George W. Bush won the election in no less controversial election battles, when votes in Florida were recounted manually. We remember what happened afterwards - we had September 11, wars in Afghanistan and Iraq, and Bush immediately scored 96 percent of support of the nation. History repeats itself.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Pravda.Ru Read article on the Russian version of Pravda.Ru What does Hillary Clinton like about Putin?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m get_prediction(real_news, convert_to_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_prediction' is not defined"
     ]
    }
   ],
   "source": [
    "real_news = \"\"\"\n",
    "Keiser Report: Trump is USA's antique hero. Clinton will be next president,nan,\"Trump is USA's antique hero. Clinton will be next president 08.11.2016 | Source: AP photo FBI Director James Comey said on November 6 that his department would not be criminally charging Hillary Clinton for revelations found in her email correspondence. Earlier, however, the FBI had flagged Clinton's email case as a file of high priority. It was said that the FBI had collected a lot of evidence. All of a sudden, it was announced that Clinton would be cleared. Pravda.Ru asked political scientist and publicist Leonid Krutakov to comment on such a development. \"\"Was it a though-out move to show that Clinton is not guilty?\"\" \"\"Did you expect a criminal case against Clinton right before the election? I thought of such a plan if Trump were winning, but now that they have cleared her name, it means that Hillary Clinton will win the election. One can be sure for 100 percent that Hillary Clinton will be the next President of the United States of America. \"\"I do not think that the FBI Director made that decision independently. This is a political figure, this is a job to which people are appointed by someone else. It is stupid to believe that one FBI director will stand up against the whole elite that prints money and runs business and international politics. The times of ancient heroes have passed. Trump has tried to become one. He has proclaimed a new era, not only in America but in the world, and the electorate that has consolidated around Trump will not go anywhere after the election. \"\"One needs another war and another threat to America to make Trump's electorate change their mind. As we remember, George W. Bush won the election in no less controversial election battles, when votes in Florida were recounted manually. We remember what happened afterwards - we had September 11, wars in Afghanistan and Iraq, and Bush immediately scored 96 percent of support of the nation. History repeats itself.\"\" Pravda.Ru Read article on the Russian version of Pravda.Ru What does Hillary Clinton like about Putin?\"\n",
    "\"\"\"\n",
    "get_prediction(real_news, convert_to_label=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
